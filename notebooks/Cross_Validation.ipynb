{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation of the ALS method using Spark\n",
    "We refer to this tutorial: http://spark.apache.org/docs/latest/ml-tuning.html#example-model-selection-via-cross-validation\n",
    "\n",
    "The tutorial was not clear: we used SKLearn to split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.display.max_columns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers_cross_validation import KFoldIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?itertools.combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    ''' Class to run the cross validation with different models\n",
    "    \n",
    "    Usage:\n",
    "    cross_val=CrossValidation(data,k,use_spark)\n",
    "    cross_val.fit(model)\n",
    "    \n",
    "    Variables:\n",
    "    self.tests_list\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(data,k,use_spark):\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        self.k=k\n",
    "        self.use_spark=use_spark\n",
    "        \n",
    "        # Initialize the k_fold_indexes\n",
    "        k_fold_indexes=KFoldIndexes(k_folds,data.shape[0])\n",
    "        \n",
    "        if use_spark:\n",
    "            self.tests_list=get_sql_from_pd(get_tests_database(data,k_fold_indexes))\n",
    "        else:\n",
    "            self.tests_list=get_tests_database(data,k_fold_indexes)\n",
    "    \n",
    "    def fit(model,**arg):\n",
    "        for comb in itertools.combinations(range(self.k),self.k-1):\n",
    "            trains=[self.tests_list for x in comb]\n",
    "            train=sc.union(trains)\n",
    "            \n",
    "            test_index=[x for x in range(self.k) if x not in comb][0]\n",
    "            test=self.tests_list[test_index]\n",
    "            \n",
    "            model.fit(train,**arg)\n",
    "            predictions=model.predict(test)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def get_tests_database(data,k_fold_indexes):\n",
    "        tests=[]\n",
    "        for i in k_fold_indexes.indexes:\n",
    "            tests.append(data.loc[i[1]])\n",
    "        return tests\n",
    "    \n",
    "    def get_sql_from_pd(df_list):\n",
    "        sql_list=[]\n",
    "        for i in df_list:\n",
    "            sql_list.append(sqlContext.createDataFrame(i).rdd)\n",
    "        return sql_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/data_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['UserID'] = train['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "train['MovieID'] = train['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "train['Rating'] = train['Prediction']\n",
    "train = train.drop(['Id', 'Prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176952"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_folds=4\n",
    "k_fold_indexes=KFoldIndexes(k_folds,train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tests_database(df,k_fold_indexes):\n",
    "    tests=[]\n",
    "    for i in k_fold_indexes.indexes:\n",
    "        tests.append(df.loc[i[1]])\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sql_from_pd(df_list):\n",
    "    sql_list=[]\n",
    "    for i in df_list:\n",
    "        print(1)\n",
    "        sql_list.append(sqlContext.createDataFrame(i))\n",
    "    return sql_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests=get_tests_database(train,k_fold_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests_sql=get_sql_from_pd(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr=tests_sql[0].rdd.union(tests_sql[1].rdd).union(tests_sql[2].rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts=tests_sql[3].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ALS.train(tr, 2, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_for_predict_RDD = ts.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rates_and_preds = ts.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sql = sqlContext.createDataFrame(train)\n",
    "train_rdd = train_sql.rdd\n",
    "train_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(train_sql.map(lambda x: (x[0],x[1],float(x[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
