{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of usage of Cross Validation while mixing models\n",
    "Not well implemented yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f304425d208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.display.max_columns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import KFoldIndexes,CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from als import predictions_ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating\n",
       "0      44        1       4\n",
       "1      61        1       3\n",
       "2      67        1       4\n",
       "3      72        1       3\n",
       "4      86        1       5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = helpers.load_csv()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with predictions_ALS function\n",
    "Example of usage of a function - for all function the usage should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index=random.sample(range(1176952),1000000)\n",
    "train_index.sort()\n",
    "test_index=list(set(range(1176952))-set(train_index))\n",
    "test_index.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training=train.loc[train_index]\n",
    "testing=train.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>3.743946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>3.754570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "      <td>3.088931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>3.223062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>3.255169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Movie    Rating\n",
       "0   114      1  3.743946\n",
       "1   152      1  3.754570\n",
       "2   310      1  3.088931\n",
       "3   333      1  3.223062\n",
       "4   355      1  3.255169"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_ALS(training,testing,sc,rank=8,lambda_=0.081, iterations=24, nonnegative=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Blending class\n",
    "To save computational power it computes the predictions for different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=CrossValidationBlending(train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.add_model(predictions_ALS,'als')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.add_params_for_model('als',{'spark_context':sc,'rank':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.evaluate_blending({'als':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=pd.concat(a.blended_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conc=np.array(pd.concat(a.blended_predictions))\n",
    "conc2=np.array(pd.concat(a.real_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c=a.real_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294238,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[c.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[c.isnull().values].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     3\n",
       "7     3\n",
       "12    3\n",
       "16    2\n",
       "18    4\n",
       "19    2\n",
       "20    3\n",
       "22    4\n",
       "25    3\n",
       "28    4\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3          0.363735\n",
       "3         -0.435135\n",
       "3          0.783914\n",
       "3          0.764041\n",
       "7          1.043640\n",
       "7          0.477089\n",
       "7         -0.130682\n",
       "7          0.407513\n",
       "12         0.474769\n",
       "12         0.132738\n",
       "12         0.936016\n",
       "12         0.186751\n",
       "16         1.125990\n",
       "16         1.002137\n",
       "16         1.986947\n",
       "16         1.258616\n",
       "18        -0.714110\n",
       "18        -0.356952\n",
       "18        -0.209815\n",
       "18        -0.805397\n",
       "19              NaN\n",
       "19              NaN\n",
       "19              NaN\n",
       "19              NaN\n",
       "20              NaN\n",
       "20              NaN\n",
       "20              NaN\n",
       "20              NaN\n",
       "22              NaN\n",
       "22              NaN\n",
       "             ...   \n",
       "1176896         NaN\n",
       "1176896         NaN\n",
       "1176904         NaN\n",
       "1176904         NaN\n",
       "1176904         NaN\n",
       "1176904         NaN\n",
       "1176908         NaN\n",
       "1176908         NaN\n",
       "1176908         NaN\n",
       "1176908         NaN\n",
       "1176913         NaN\n",
       "1176913         NaN\n",
       "1176913         NaN\n",
       "1176913         NaN\n",
       "1176929         NaN\n",
       "1176929         NaN\n",
       "1176929         NaN\n",
       "1176929         NaN\n",
       "1176934         NaN\n",
       "1176934         NaN\n",
       "1176934         NaN\n",
       "1176934         NaN\n",
       "1176937         NaN\n",
       "1176937         NaN\n",
       "1176937         NaN\n",
       "1176937         NaN\n",
       "1176950         NaN\n",
       "1176950         NaN\n",
       "1176950         NaN\n",
       "1176950         NaN\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc-conc2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum((conc-conc2)**2)/conc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CrossValidationBlending:\n",
    "    \n",
    "    \n",
    "    def __init__(self,data,k):\n",
    "        ''' Initialization function. It creates self.tests_list, the list of all the test dataframe\n",
    "        \n",
    "        @ params\n",
    "            - data, the input dataframe\n",
    "            - k, the number of splits in the cross validation\n",
    "        '''\n",
    "        \n",
    "        # Initialize static class variables\n",
    "        self.models={} # Dict to store all the model functions\n",
    "        self.params={} # Dict to store the params with which running each model\n",
    "        self.predictions={} # Dict to store the predictions for each model with the given parameters\n",
    "        self.real_values=[] # List to store the real values for each chunk\n",
    "        self.blended_predictions=[]\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        self.k=k\n",
    "        \n",
    "        # Initialize the k_fold_indexes\n",
    "        k_fold_indexes=KFoldIndexes(k,data.shape[0])\n",
    "        \n",
    "        if k>1:\n",
    "            self.tests_list=self.get_tests_database(data,k_fold_indexes)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def add_model(self,function, name):\n",
    "        self.models[name]=function\n",
    "\n",
    "    def add_params_for_model(self,model_name,params_dict):\n",
    "        if model_name not in self.models:\n",
    "            print('Warning: Adding parameters for a non-existing model')\n",
    "        self.params[model_name]=params_dict\n",
    "        self.compute_predictions(model_name)\n",
    "        \n",
    "    def compute_predictions(self,model):\n",
    "        \n",
    "        for model_name in self.models:\n",
    "            if model_name!=model:\n",
    "                continue\n",
    "            self.real_values=[]\n",
    "            \n",
    "            function=self.models[model_name]\n",
    "            try:\n",
    "                arguments=self.params[model_name]\n",
    "            except:\n",
    "                print('Arguments not available for model',model_name)\n",
    "                \n",
    "            self.predictions[model_name]=[]\n",
    "            for comb in itertools.combinations(range(self.k),self.k-1):\n",
    "                trains=[self.tests_list[x] for x in comb]\n",
    "                train=pd.concat(trains)\n",
    "                \n",
    "                test_index=[x for x in range(self.k) if x not in comb][0]\n",
    "                test=self.tests_list[test_index]\n",
    "                \n",
    "                self.real_values.append(test.Rating)\n",
    "                self.predictions[model_name].append(function(train,test,**arguments))\n",
    "            \n",
    "    def evaluate_blending(self,blending_dict):        \n",
    "        if len(blending_dict)!=len(self.predictions):\n",
    "            print('Different lenght of blending_dict and predictions')\n",
    "            raise()\n",
    "        \n",
    "        self.blended_predictions=[]\n",
    "        for i in range(self.k):\n",
    "            prediction=0*self.real_values[0]\n",
    "            \n",
    "            for model_name in blending_dict:\n",
    "                prediction+=blending_dict[model_name]*self.predictions[model_name][i].Rating\n",
    "                \n",
    "            self.blended_predictions.append(prediction)\n",
    "        \n",
    "    def get_tests_database(self,data,k_fold_indexes):\n",
    "        '''Internal function to get the list of test pandas dataframe'''\n",
    "        tests=[]\n",
    "        for i in k_fold_indexes.indexes:\n",
    "            tests.append(data.loc[i[1]])\n",
    "        return tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of simple Cross Validation on a single model\n",
    "Old part - it will be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ALSModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,**arg):\n",
    "        self.model = ALS.train(data, **arg)\n",
    "    \n",
    "    def predict(self,data):\n",
    "        data_for_preditions=data.map(lambda x: (x[0], x[1]))\n",
    "        self.predictions = self.model.predictAll(data_for_preditions).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    \n",
    "    def evaluate(self,data):\n",
    "        rates_and_preds = data.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(self.predictions)\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv=CrossValidation(train,4,True,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = [8]\n",
    "lambdas = [0.08,0.081,0.082,0.083,0.084,0.085,0.086,0.087,0.088,0.089,0.09]\n",
    "numIters = [24]\n",
    "nbr_models = len(ranks)*len(lambdas)*len(numIters)\n",
    "\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    try:\n",
    "        print(rank,lmbda,numIter)\n",
    "        validationRmse = cv.evaluate(ALSModel(),rank=rank,lambda_=lmbda, iterations=numIter, nonnegative=True)\n",
    "        validationRmse = np.mean(validationRmse)\n",
    "        print(\"Model %i/%i: RMSE (validation) = %f\" %(i+1, nbr_models, validationRmse))\n",
    "        print(\"  Trained with rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter))\n",
    "        print(\"\")\n",
    "        if (validationRmse < bestValidationRmse):\n",
    "#             bestModel = model\n",
    "            bestValidationRmse = validationRmse\n",
    "            bestRank = rank\n",
    "            bestLambda = lmbda\n",
    "            bestNumIter = numIter\n",
    "    except:\n",
    "        print(\"Model %i/%i failed!\" %(i+1, nbr_models))\n",
    "        print(\"  Parameters: rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter))\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "# Evaluate the best model on the training set\n",
    "print(\"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "  + \"and numIter = %d, and its RMSE on the training set is %f\" % (bestNumIter, bestValidationRmse))\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# testRmse = computeRMSE(bestModel, test_for_predict_RDD, test_RDD)\n",
    "# print(\"RMSE on the test set: %f\"%(testRmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/sampleSubmission.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare test for RDD\n",
    "test_prep = test\n",
    "test_prep['UserID'] = test_prep['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "test_prep['MovieID'] = test_prep['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "test_prep['Rating'] = test_prep['Prediction']\n",
    "test_prep = test_prep.drop(['Prediction', 'Id'], axis=1)\n",
    "test_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we transform it using sqlContect\n",
    "test_sql = sqlContext.createDataFrame(test_prep)\n",
    "test_rdd = test_sql.rdd\n",
    "test_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestModel=ALSModel()\n",
    "bestModel.fit(train_rdd,rank=8,lambda_=0.081, iterations=24, nonnegative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestModel.predict(test_rdd)\n",
    "predictions=bestModel.predictions\n",
    "# predictions = bestModel.predictAll(test_RDD_Kaggle).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = predictions.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df['UserID'] = pred_df['_1'].apply(lambda x: x['_1'])\n",
    "pred_df['MovieID'] = pred_df['_1'].apply(lambda x: x['_2'])\n",
    "pred_df['Rating'] = pred_df['_2']\n",
    "pred_df = pred_df.drop(['_1', '_2'], axis=1)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df = pred_df.sort_values(by=['MovieID', 'UserID'])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.index = range(len(pred_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Prediction'] = pred_df['Rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.drop(['UserID', 'MovieID', 'Rating'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('pred_pyspark_als.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
