{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation of the ALS method using Spark\n",
    "We refer to this tutorial: http://spark.apache.org/docs/latest/ml-tuning.html#example-model-selection-via-cross-validation\n",
    "\n",
    "The tutorial was not clear: we used SKLearn to split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.display.max_columns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers_cross_validation import KFoldIndexes,CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ALSModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,**arg):\n",
    "        self.model = ALS.train(data, **arg)\n",
    "    \n",
    "    def predict(self,data):\n",
    "        data_for_preditions=data.map(lambda x: (x[0], x[1]))\n",
    "        self.predictions = self.model.predictAll(data_for_preditions).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    \n",
    "    def evaluate(self,data):\n",
    "        rates_and_preds = data.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(self.predictions)\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/data_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['UserID'] = train['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "train['MovieID'] = train['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "train['Rating'] = train['Prediction']\n",
    "train = train.drop(['Id', 'Prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176952"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv=CrossValidation(train,4,True,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = [7,8,9]\n",
    "lambdas = [0.08,0.085,0.09,0.095,0.1]\n",
    "numIters = [20]\n",
    "nbr_models = len(ranks)*len(lambdas)*len(numIters)\n",
    "\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.08 20\n",
      "Model 1/15: RMSE (validation) = 0.991639\n",
      "  Trained with rank = 7, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "7 0.085 20\n",
      "Model 2/15: RMSE (validation) = 0.991673\n",
      "  Trained with rank = 7, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "7 0.09 20\n",
      "Model 3/15: RMSE (validation) = 0.991241\n",
      "  Trained with rank = 7, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "7 0.095 20\n",
      "Model 4/15: RMSE (validation) = 0.991421\n",
      "  Trained with rank = 7, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "7 0.1 20\n",
      "Model 5/15: RMSE (validation) = 0.992471\n",
      "  Trained with rank = 7, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "8 0.08 20\n",
      "Model 6/15: RMSE (validation) = 0.991252\n",
      "  Trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "8 0.085 20\n",
      "Model 7/15: RMSE (validation) = 0.991237\n",
      "  Trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "8 0.09 20\n",
      "Model 8/15: RMSE (validation) = 0.991082\n",
      "  Trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "8 0.095 20\n",
      "Model 9/15: RMSE (validation) = 0.991452\n",
      "  Trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "8 0.1 20\n",
      "Model 10/15: RMSE (validation) = 0.991691\n",
      "  Trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "9 0.08 20\n",
      "Model 11/15: RMSE (validation) = 0.991756\n",
      "  Trained with rank = 9, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "9 0.085 20\n",
      "Model 12/15: RMSE (validation) = 0.991312\n",
      "  Trained with rank = 9, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "9 0.09 20\n",
      "Model 13/15: RMSE (validation) = 0.991230\n",
      "  Trained with rank = 9, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "9 0.095 20\n",
      "Model 14/15: RMSE (validation) = 0.991661\n",
      "  Trained with rank = 9, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "9 0.1 20\n",
      "Model 15/15: RMSE (validation) = 0.991921\n",
      "  Trained with rank = 9, lambda = 0.1, and numIter = 20.\n",
      "\n",
      "The best model was trained with rank = 8 and lambda = 0.1, and numIter = 20, and its RMSE on the training set is 0.991082\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    try:\n",
    "        print(rank,lmbda,numIter)\n",
    "        validationRmse = cv.evaluate(ALSModel(),rank=rank,lambda_=lmbda, iterations=numIter)\n",
    "        validationRmse = np.mean(validationRmse)\n",
    "        print(\"Model %i/%i: RMSE (validation) = %f\" %(i+1, nbr_models, validationRmse))\n",
    "        print(\"  Trained with rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter))\n",
    "        print(\"\")\n",
    "        if (validationRmse < bestValidationRmse):\n",
    "#             bestModel = model\n",
    "            bestValidationRmse = validationRmse\n",
    "            bestRank = rank\n",
    "            bestLambda = lmbda\n",
    "            bestNumIter = numIter\n",
    "    except:\n",
    "        print(\"Model %i/%i failed!\" %(i+1, nbr_models))\n",
    "        print(\"  Parameters: rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter))\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "# Evaluate the best model on the training set\n",
    "print(\"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "  + \"and numIter = %d, and its RMSE on the training set is %f\" % (bestNumIter, bestValidationRmse))\n",
    "\n",
    "# # Evaluate the best model on the test set\n",
    "# testRmse = computeRMSE(bestModel, test_for_predict_RDD, test_RDD)\n",
    "# print(\"RMSE on the test set: %f\"%(testRmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests=get_tests_database(train,k_fold_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests_sql=get_sql_from_pd(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.union(tests_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr=tests_sql[0].rdd.union(tests_sql[1].rdd).union(tests_sql[2].rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts=tests_sql[3].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ALS.train(tr, 2, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_for_predict_RDD = ts.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rates_and_preds = ts.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sql = sqlContext.createDataFrame(train)\n",
    "train_rdd = train_sql.rdd\n",
    "train_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(train_sql.map(lambda x: (x[0],x[1],float(x[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
